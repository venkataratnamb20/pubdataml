{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkataratnamb20/pubdataml/blob/main/pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# colab- examples"
      ],
      "metadata": {
        "id": "yTbY2Je6DhGo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfIMtw6BaiO1"
      },
      "source": [
        "## Pandas DataFrame: Create from lists of values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ5S72eoaiuA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "last_names = ['Connor', 'Connor', 'Reese']\n",
        "first_names = ['Sarah', 'John', 'Kyle']\n",
        "df = pd.DataFrame({\n",
        "  'first_name': first_names,\n",
        "  'last_name': last_names,\n",
        "})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6CMhXZas7m"
      },
      "source": [
        "## Pandas DataFrame: Rename multiple Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PidN8TlvatXt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'Year': [2016, 2015, 2014, 2013, 2012],\n",
        "    'Top Animal': ['Giant panda', 'Chicken', 'Pig', 'Turkey', 'Dog']\n",
        "})\n",
        "\n",
        "df.rename(columns={\n",
        "    'Year': 'Calendar Year',\n",
        "    'Top Animal': 'Favorite Animal',\n",
        "}, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3GmnRDV--F_"
      },
      "source": [
        "## Pandas DataFrame: Query by regexp (regular expression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2_DTKp-9v2A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle', 'Joe'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese', 'Bonnot'],\n",
        "})\n",
        "\n",
        "df[df.last_name.str.match('.*onno.*')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR_tSBKZPCHe"
      },
      "source": [
        "## Pandas DataFrame: Query by variable value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emvt3RwC4U2L"
      },
      "source": [
        "Evaluate a variable as the value to find."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5chfuU3RPItU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese'],\n",
        "})\n",
        "\n",
        "foo = 'Connor'\n",
        "df.query('last_name == @foo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHFe_2xK3WI7"
      },
      "source": [
        "## Pandas DataFrame: Query using variable value as a column name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8PqFCcW4y6z"
      },
      "source": [
        "Evaluate a variable, to use its value as the name of a column in a query.\n",
        "\n",
        "E.g. Query for rows where `John` is the value in the column named `first_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbXpFR93PRtc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data={\n",
        "  'first_name': ['Sarah', 'John', 'Kyle'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese'],\n",
        "})\n",
        "\n",
        "column_name = 'first_name'\n",
        "df.query(f\"`{column_name}` == 'John'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIgQb_ICbNu9"
      },
      "source": [
        "## Pandas DataFrame: Query by Timestamp above a value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PAn5prJbOXk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'time': ['2022-09-14 00:52:00-07:00', '2022-09-14 00:52:30-07:00',\n",
        "           '2022-09-14 01:52:30-07:00'],\n",
        "  'letter': ['A', 'B', 'C'],\n",
        "})\n",
        "df['time'] = pd.to_datetime(df.time)\n",
        "\n",
        "df.query('time >= \"2022-09-14 00:52:30-07:00\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEFOgYwT0jiY"
      },
      "source": [
        "## Pandas DataFrame: Query for Timestamp between two values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gznADrAnbXGY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'time': ['2022-09-14 00:52:00-07:00', '2022-09-14 00:52:30-07:00',\n",
        "           '2022-09-14 01:52:30-07:00'],\n",
        "  'letter': ['A', 'B', 'C'],\n",
        "})\n",
        "df['time'] = pd.to_datetime(df.time)\n",
        "\n",
        "begin_ts = '2022-09-14 00:52:00-07:00'\n",
        "end_ts = '2022-09-14 00:54:00-07:00'\n",
        "\n",
        "df.query('@begin_ts <= time < @end_ts')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zoeyh7ndKKN"
      },
      "source": [
        "## Pandas DataFrame: Filter by Timestamp in DatetimeIndex using `.loc[]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B_YCZUrbaFG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'time': ['2022-09-14 00:52:00-07:00', '2022-09-14 00:52:30-07:00',\n",
        "           '2022-09-14 01:52:30-07:00'],\n",
        "  'letter': ['A', 'B', 'C'],\n",
        "})\n",
        "df['time'] = pd.to_datetime(df.time)\n",
        "df.set_index('time', inplace=True)\n",
        "\n",
        "df.loc['2022-09-14':'2022-09-14 00:53']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDscd8p3hOqz"
      },
      "source": [
        "## Pandas DataFrame: Filter by Timestamp using TimeDelta string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoRYanJrVV5g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'time': ['2022-09-14 00:52:00-07:00', '2022-09-14 00:52:30-07:00',\n",
        "           '2022-09-14 01:52:30-07:00'],\n",
        "  'letter': ['A', 'B', 'C'],\n",
        "})\n",
        "df['time'] = pd.to_datetime(df.time)\n",
        "\n",
        "def rows_in_time_range(df, time_column, start_ts_str, timedelta_str):\n",
        "  # Return rows from df, where start_ts < time_column <= start_ts + delta.\n",
        "  # start_ts_str can be a date '2022-09-01' or a time '2022-09-14 00:52:00-07:00'\n",
        "  # timedelta_str examples: '2 minutes'  '2 days 2 hours 15 minutes 30 seconds'\n",
        "  start_ts = pd.Timestamp(start_ts_str).tz_localize('US/Pacific')\n",
        "  end_ts = start_ts + pd.to_timedelta(timedelta_str)\n",
        "  return df.query(\"@start_ts <= {0} < @end_ts\".format(time_column))\n",
        "\n",
        "rows_in_time_range(df, 'time', '2022-09-14 00:00', '52 minutes 31 seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyrfPExcbjFY"
      },
      "source": [
        "## Pandas: Describe Timestamp values in a column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1-ozcpHbitV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'time': ['2022-09-14 00:52:00-07:00', '2022-09-14 00:52:30-07:00',\n",
        "           '2022-09-14 01:52:30-07:00'],\n",
        "  'letter': ['A', 'B', 'C'],\n",
        "})\n",
        "df['time'] = pd.to_datetime(df.time)\n",
        "\n",
        "df['time'].describe(datetime_is_numeric=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrWXmdmOcA6F"
      },
      "source": [
        "## Pandas DataFrame: Explode a column containing dictionary values into multiple columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcbWC_o5Bq6J"
      },
      "source": [
        "This code transforms or splits the dictionary column into many columns.\n",
        "\n",
        "E.g. The output DataFrame of this cell will have columns named [`date, letter, fruit, weather`]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2225FVJacBYs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'date': ['2022-09-14', '2022-09-15', '2022-09-16'],\n",
        "  'letter': ['A', 'B', 'C'],\n",
        "  'dict' : [{ 'fruit': 'apple', 'weather': 'aces'},\n",
        "            { 'fruit': 'banana', 'weather': 'bad'},\n",
        "            { 'fruit': 'cantaloupe', 'weather': 'cloudy'}],\n",
        "})\n",
        "\n",
        "pd.concat([df.drop(['dict'], axis=1), df['dict'].apply(pd.Series)], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIjbg2DUki9C"
      },
      "source": [
        "## Pandas DataFrame: Extract values using regexp (regular expression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7v3bFUmkidS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'request': ['GET /index.html?baz=3', 'GET /foo.html?bar=1'],\n",
        "})\n",
        "\n",
        "df['request'].str.extract('GET /([^?]+)\\?', expand=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8mikXMvjahc"
      },
      "source": [
        "## Pandas Timestamp: Convert string to Timestamp, using date only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smKFFysmlQOx"
      },
      "source": [
        "I.e. Midnight on the given date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPum-jBojGeF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.Timestamp('9/27/22').tz_localize('US/Pacific')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlE2B9gYlUto"
      },
      "source": [
        "## Pandas Timestamp: Convert string to Timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZeu0qa3jpcu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.Timestamp('9/27/22 06:59').tz_localize('US/Pacific')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-p8mTaHlE3I"
      },
      "source": [
        "## Pandas: Create a TimeDelta using `unit`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iYqXT8qmEZn"
      },
      "source": [
        "From an integer.\n",
        "`unit` is a string, defaulting to `ns`. Possible values:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNo40II-lD2q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.to_timedelta(1, unit='h')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMQyJtg5mmCx"
      },
      "source": [
        "## Pandas: Create a TimeDelta using available kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh4w12fS4v0J"
      },
      "source": [
        "Example keyworded args: {days, seconds, microseconds, milliseconds, minutes, hours, weeks}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giw4M16gmlkK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.Timedelta(days=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXR7N2sCmA-_"
      },
      "source": [
        "## Pandas: Create a TimeDelta from a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SjGanWwl0XG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.Timedelta('2 days 2 hours 15 minutes 30 seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnwXL2jnEO0V"
      },
      "source": [
        "## Pandas: Replace NaN values in a Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeKjQOEJEOVh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'dogs': [5, 10, np.nan, 7],\n",
        "})\n",
        "\n",
        "df['dogs'].replace(np.nan, 0, regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCuIYAhHJimy"
      },
      "source": [
        "## Pandas DataFrame: Drop duplicate rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjBDuqQSEgml"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle', 'Joe'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese', 'Bonnot'],\n",
        "})\n",
        "df.set_index('last_name', inplace=True)\n",
        "\n",
        "df.loc[~df.index.duplicated(), :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy-BKNgWUwnQ"
      },
      "source": [
        "## Pandas DataFrame: Ignore one Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y00BW8DOUxGs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle', 'Joe'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese', 'Bonnot'],\n",
        "})\n",
        "\n",
        "df.loc[:, df.columns!='last_name']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vp6gD9OVo1Z"
      },
      "source": [
        "## Pandas DataFrame: Intersect Indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3kdge_GVxO3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "terminator_df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese'],\n",
        "})\n",
        "terminator_df.set_index('first_name', inplace=True)\n",
        "\n",
        "buckaroo_df = pd.DataFrame({\n",
        "  'first_name': ['John', 'John', 'Buckaroo'],\n",
        "  'last_name': ['Parker', 'Whorfin', 'Banzai'],\n",
        "})\n",
        "buckaroo_df.set_index('first_name', inplace=True)\n",
        "\n",
        "terminator_df.index.intersection(buckaroo_df.index).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVh1EtmVV0Qb"
      },
      "source": [
        "## Pandas DataFrame: Select all rows from A that are not in B, using the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUazjSSUV_45"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "terminator_df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese'],\n",
        "})\n",
        "terminator_df.set_index('first_name', inplace=True)\n",
        "\n",
        "buckaroo_df = pd.DataFrame({\n",
        "  'first_name': ['John', 'John', 'Buckaroo'],\n",
        "  'last_name': ['Parker', 'Whorfin', 'Banzai'],\n",
        "})\n",
        "buckaroo_df.set_index('first_name', inplace=True)\n",
        "\n",
        "terminator_df[~terminator_df.index.isin(buckaroo_df.index)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVTdtZJAWItJ"
      },
      "source": [
        "## Pandas DataFrame: Select rows by an attribute of a column value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2XfO20JWYy7"
      },
      "source": [
        "Use the Series `map()` method.\n",
        "E.g. To filter by the length of a column values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmuXV7bzVnU-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese'],\n",
        "})\n",
        "\n",
        "df[df['last_name'].map(len) == 5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMQ60B9Gghjh"
      },
      "source": [
        "## Pandas DataFrame: Sort the count of rows grouped on columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4nwrfh-gVxX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'first_name': ['Sarah', 'John', 'Kyle'],\n",
        "  'last_name': ['Connor', 'Connor', 'Reese'],\n",
        "})\n",
        "\n",
        "df.groupby(['last_name']).size().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRl1d3PY0ulI"
      },
      "source": [
        "## Pandas DataFrame: Reshape to have 1 row per value in a list column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Pberyl1KTk"
      },
      "source": [
        "Creates a new DataFrame that is a transformed version of the input. E.g.\n",
        "*   Input: df with a column named `msg_ids` that is a list of values (i.e. many per row, at least in some rows).\n",
        "*   Output: new_df which has 1 row per unique value found in any of the original `msg_ids` lists, with that value in a new column named `msg_id`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvPNQJFn090X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'date': ['9/1/22', '9/2/22', '9/3/22'],\n",
        "  'action': ['Add', 'Update', 'Delete'],\n",
        "  'msg_ids': [[1, 2, 3], [], [2, 3]],\n",
        "})\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "\n",
        "temp_series = df['msg_ids'].apply(pd.Series, 1).stack()\n",
        "temp_series.index = temp_series.index.droplevel(-1)\n",
        "temp_series.name = 'msg_id'\n",
        "new_df = temp_series.to_frame()\n",
        "new_df.set_index('msg_id', inplace=True)\n",
        "new_df.loc[~new_df.index.duplicated(), :] # Drop duplicates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I14ORpEPP4Wr"
      },
      "source": [
        "## Pandas: DataFrames: Group Timeseries by Frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yycF10l6Qe8Y"
      },
      "source": [
        "You can group timestamped data into intervals of arbitrary duration using a Grouper object to specify groupby instructions.  The `freq` parameter is a string that may contain an integer followed by an [offset alias](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).  E.g. To see output for 2 minute long intervals:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Eh3efwfQeFr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'time': ['2022-09-01 00:00:01-07:00', '2022-09-01 00:00:02-07:00',\n",
        "           '2022-09-01 00:01:00-07:00', '2022-09-01 00:02:00-07:00',\n",
        "           '2022-09-01 00:03:00-07:00', '2022-09-01 00:04:00-07:00',\n",
        "           '2022-09-01 00:05:00-07:00', '2022-09-01 00:07:00-07:00'],\n",
        "  'requests': [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "})\n",
        "df['time'] = pd.to_datetime(df.time)\n",
        "\n",
        "df.groupby(pd.Grouper(key='time', freq='2min')).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vb-work"
      ],
      "metadata": {
        "id": "8-ig2YxZDbtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Udacity: Artificial Intellegence\n",
        "- [github/udacity-courses](https://github.com/udacity/AI_fundamentals/)\n",
        "Books\n",
        "\n",
        "- [artificial intellegence modern approach by russel](http://aima.cs.berkeley.edu/)\n",
        "-"
      ],
      "metadata": {
        "id": "-aAkqIsyE4xj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_POvTXtIDdYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topics\n",
        "- Advanced Search\n",
        "- MinMax Algorithm\n",
        "- Alpha-Beta Pruning\n",
        "- Evaluation Functions\n",
        "- Isolation Game Player"
      ],
      "metadata": {
        "id": "12B7BLMhE84S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "imwKfJU0FK2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Isolation Game"
      ],
      "metadata": {
        "id": "94cUUny5Gk_B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyaZ2efuGmWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI With Azure\n",
        "\n",
        "- [Artificial intelligence (AI) vs. machine learning (ML)](https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/artificial-intelligence-vs-machine-learning)\n",
        "- [Artificial Intelligence For Industrial Applications](https://semiengineering.com/artificial-intelligence-for-industrial-applications/)\n",
        "-  \n",
        "-"
      ],
      "metadata": {
        "id": "n8LCsJ3ILlnh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "914Ilt_zOFqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Responsible AI\n",
        "- [Tools and practices](https://www.microsoft.com/en-us/ai/tools-practices)\n",
        "- [microsoft: haxtoolkit-demo](https://www.microsoft.com/en-us/haxtoolkit/demo/)\n",
        "- [Responsible AI with Azure](https://azure.microsoft.com/en-us/solutions/ai/responsible-ai-with-azure/)\n",
        "-"
      ],
      "metadata": {
        "id": "KO_3GqBWOF7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML\n",
        "\n",
        "Key Machine\n",
        "Learning Concepts\n",
        "\n",
        "Approaches\n",
        "to ML\n",
        "\n",
        "Core Tasks in Building a Solution\n",
        "\n",
        "Azure ML + Automated ML\n",
        "- Ingest and Prepare Data\n",
        "- Feature Engineering + Feature Selection\n",
        "- Model Training and Evaluation\n",
        "- Model Deployment and Management\n",
        "- Testing Deployed Models\n",
        "\n",
        "Data process\n",
        "\n",
        "Key Phases of the Data Science Process\n",
        "There are five key steps to the data science process:\n",
        "\n",
        "- `Collect data` We need to be able to collect reliable data and ensure that we understand its origin, quality, and meaning.\n",
        "- ``Prepare data. The next phase in the data science process is data preparation. This can take up an enormous percentage of total time--estimates range upwards of 80-90%.\n",
        "- `Train a model` In this phase, we apply appropriate algorithms to our data, resulting in a trained model. Depending on the algorithm, training may take a considerable amount of time. For example, certain applications of neural networks may take over a month to train fully. Generally, however, model training does not take that much time.\n",
        "- `Evaluate the model` After we have trained a model, we want to ensure that it meets our expectations in terms of quality. Because the real world is always more complicated than our training data set, we want to make sure that the results look reasonable on non-training before pushing a model out to production. This helps us avoid overfitting to the training data.\n",
        "- `Deploy the model` Having a model is great, but having it available for use is the natural next step. Historically, deploying a model typically meant rewriting it into a \"production\" development language like C or C++. Today, it is easy to run a microservice in a language like R or Python and handle prediction needs.\n",
        "\n",
        "\n",
        "$$ Collect => data => Prepare => data => Train => model => Evaluate => Deploy $$\n",
        "$$ model => Data => CSV => Trained Model => Model Evaluation => Data => CSV$$\n",
        "\n",
        "### Choosing an Algorithm\n",
        "\n",
        "- Accuracy\n",
        "- Speed\n",
        "- Explainability\n",
        "- Existence\n",
        "\n",
        "### Model Evaluation Metrics for Regression\n",
        "| Metric | Best Use |\n",
        "|--------|----------|\n",
        "| R2 | Linear regression models |\n",
        "| Mean Absolute Error (MAE) | Not much variance in observed values |\n",
        "| Mean Absolute Percent Error (MAPE)  | Variance in actual values is high Actual value is never 0 |\n",
        "| Root Mean Square Error (RMSE) | Larger discrepancies are way worse than smaller discrepancies |\n",
        "| Root Mean Square Log Error (RMSLE) | Larger percentage discrepancies are way worse |\n",
        "\n",
        "\n",
        "### Model Evaluation Metrics for Classification\n",
        "\n",
        "Based on the type of model, there are several evaluation measures available. The most common classes of algorithm we want to test are `regression` and `classification`.\n",
        "\n",
        "For classification, we have the `confusion matrix`, which allows us to define a variety of important measures. Three of these important measures are:\n",
        "\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "\n",
        "\n",
        "### New Terms\n",
        "\n",
        "- Microservice: A lightweight, independent service. Typically, microservices have one job and communicate with each other using well-defined operations.\n",
        "- Label: The thing we want to predict.\n",
        "- Feature: Inputs which help us understand what affects the label.\n",
        "- Overfitting: A situation which happens when a trained model latches onto the particular relationships within a training data set, but those particulars are not always indicative of the broader world.\n",
        "- R^2 (R-squared): An evaluation measure for linear regression models which ranges from 0-1, where 1 is the highest possible score.\n",
        "- Mean Absolute Error (MAE): An evaluation measure for any regression model. It is the average difference between predicted and actual values. This works well when dealing with small ranges of numbers.\n",
        "- Mean Absolute Percent Error (MAPE): An evaluation measure for any regression model. It is the percentage difference between the predicted and actual values. If the actual value is 0, MAPE will fail with a divide by 0 error, so it is not a good measure if the actual value can be 0. MAPE works best when you have large ranges of numbers.\n",
        "- Root Mean Square Error (RMSE): An evaluation measure for any regression model. RMSE works best when you are concerned with large differences between the predicted and actual values.\n",
        "- Root Mean Square Log Error (RMSLE): An evaluation measure for any regression model. RMSLE works best when you are concerned with large percentage differences between the predicted and actual values.\n",
        "- Confusion matrix: A table representing predicted versus actual values for a classification problem. A classic two-class confusion matrix has four boxes. Using \"Yes\" and \"No\" as the two classes, these four boxes are:\n",
        "- True Positive: we predicted Yes correctly\n",
        "- False Positive: we predicted Yes but it was really No\n",
        "- False Negative: we predicted No but it was really Yes\n",
        "- True Negative: we predicted No correctly\n",
        "- Accuracy (classification): A measure which is defined as the number of correct predictions divided by the total number of predictions.\n",
        "- Precision: A measure which calculates how frequently our predicted value is correct. It is defined as True Positives / (True Positives + False Positives).\n",
        "- Recall: A measure which calculates how frequently we correctly predict a value. It is defined as True Positives / (True Positives + False Negatives).\n",
        "- Receiver Operating Characteristic (ROC) curve: A plot which represents true positive versus false positive rates for a two-class model.\n",
        "- Area Under the Curve: the percentage of area underneath the ROC curve. This is a measure of how accurate the two-class model is, with numbers closer to 1 being better.\n",
        "\n",
        "### There are four approaches to machine learning:\n",
        "\n",
        "- Supervised learning: We have a known good answer for our label. The most common examples of this include classification and regression. This is by far the most common type of machine learning in the business world, as we generally develop models to solve known business problems, such as forecasting how much revenue the company will earn in the next quarter.\n",
        "- Unsupervised learning: We do not have labels for our data. We use unsupervised learning techniques to try to discover what those labels should be. Clustering is the most common example of this.\n",
        "- Semi-supervised learning: We have a small percentage of data with labels and a large percentage of unlabeled data. Perform supervised learning against the labeled data and then cluster the unlabeled data to find the nearest labeled points.\n",
        "- Reinforcement learning: We train an agent to observe its environment and use those environmental clues to make a decision. For example, we might train a robot to sweep through a house in the least amount of time without getting stuck or sweeping over the same spots too frequently.\n",
        "\n",
        "*Supervised Learning*\n",
        "\n",
        "We have a known good answer for our label\n",
        "Use this to train a model to predict labels for new data\n",
        "\n",
        "- Classification\n",
        "- Regression\n",
        "- Anomaly Detection\n",
        "- Similarity Learning\n",
        "- Representation Learning\n",
        "\n",
        "*Unsupervised Learning*\n",
        "\n",
        "Do not have known good answers for the problem we want to solve\n",
        "Train a model to discover patterns that humans did not define\n",
        "\n",
        "- Clustering\n",
        "- Anomaly\n",
        "- Detection\n",
        "- Representation Learning\n",
        "\n",
        "*Semi-Supervised Learning*\n",
        "\n",
        "- Small amount of labeled data and a large amount of unlabeled data.\n",
        "- Learn from the labeled data\n",
        "- Apply what we learn to the \"nearest\" unlabeled data\n",
        "\n",
        "*Reinforcement Learning*\n",
        "\n",
        "- Train an agent to observe its environment\n",
        "- Use those environmental clues to make a decision\n",
        "- Agent is rewarded based on nearness to the optimal choice\n",
        "\n",
        "*Summary*\n",
        "There are five core tasks involved in building a machine learning solution:\n",
        "\n",
        "- Ingest and prepare data\n",
        "- Feature selection and feature engineering\n",
        "- Model training and evaluation\n",
        "- Model deployment and management\n",
        "- Testing deployed models\n",
        "\n",
        "### New Terms\n",
        "\n",
        "- `Azure Machine Learning Studio:` The integrated development environment (IDE) for Azure Machine Learning.\n",
        "- `Pipeline (Azure ML):` A collection of components connected together in a defined order. The metaphor represents how data moves from a source (an initial dataset) and flows through components until it reaches a destination. There are two types of pipeline:` training pipelines and inference pipelines.\n",
        "- `Run (Azure ML):` An attempt to train a model in Azure Machine Learning. This can be done through a pipeline in the Azure ML designer or through Automated ML.\n",
        "- `Experiment (Azure ML):` A collection of trials used to validate a user's hypothesis. An experiment may contain multiple runs of pipelines.\n",
        "- `Compute (Azure ML):` Virtual machine resources which are dedicated to performing tasks in Azure Machine Learning. Compute may include individual virtual machines (VMs), typically configured as data science VMs, or it may include a cluster of VMs intended for training and inference pipeline executions.\n",
        "- `Data Labeling:` This functionality allows you to label images as part of an image classification project.\n",
        "- `Linked Services:` This functionality allows you to integrate Azure Machine Learning with other Azure services. At present, the only linked service offering is to connect to Azure Synapse Analytics, which is a modern data warehousing offering on Azure.\n",
        "- `Pipeline Asset:` A component available within Azure Machine Learning. This includes datasets you have imported, sample datasets which come with the service, and different components to transform, train, evaluate, and deploy models.\n",
        "- `Node (input, output):` An input or output connection point on a component. Each component will have 0 to 3 input nodes and 0 to 3 output nodes. Each input or output node has a specific type, such as DataFrameDirectory, TransformationDirectory, or UntrainedModelDirectory. An input of DataFrameDirectory can only attach to an output of the same type.\n",
        "- `Source node:` A node with no inputs. An example of a source node is any dataset you bring onto the canvas.\n",
        "- `Sink node:` A node with no outputs. An example of a sink node is Web Service Output.\n"
      ],
      "metadata": {
        "id": "oTbweFhjQecR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Glossary\n",
        "\n",
        "For your reference, here are all the new terms we introduced in this lesson:\n",
        "\n",
        "- Accuracy (classification): A measure which is defined as the number of correct predictions divided by the total number of predictions.\n",
        "- Area Under the Curve: the percentage of area underneath the ROC curve. This is a measure of how accurate the two-class model is, with numbers closer to 1 being better.\n",
        "- Azure Machine Learning Studio: The integrated development environment (IDE) for Azure Machine Learning.\n",
        "- Compute (Azure ML): Virtual machine resources which are dedicated to performing tasks in Azure Machine Learning. Compute may include individual virtual machines (VMs), typically configured as data science VMs, or it may include a cluster of VMs intended for training and inference pipeline executions.\n",
        "- Confusion matrix: A table representing predicted versus actual values for a classification problem. A classic two-class confusion matrix has four boxes. Using \"Yes\" and \"No\" as the two classes, these four boxes are:\n",
        "- True Positive: we predicted Yes correctly\n",
        "- False Positive: we predicted Yes but it was really No\n",
        "- False Negative: we predicted No but it was really Yes\n",
        "- True Negative: we predicted No correctly\n",
        "- Data Labeling: This functionality allows you to label images as part of an image classification project.\n",
        "- Experiment (Azure ML): A collection of trials used to validate a user's hypothesis. An experiment may contain multiple runs of pipelines.\n",
        "- Feature: Inputs which help us understand what affects the label.\n",
        "- Feature engineering: Creating new features from existing data. This might include calculating new features, translating a street address into latitude and longitude, or parsing passages of text for meaning.\n",
        "- Feature selection: Removing a column from consideration when training a model.\n",
        "- Label: The thing we want to predict.\n",
        "- Linked Services: This functionality allows you to integrate Azure Machine Learning with other Azure services. At present, the only linked service offering is to connect to Azure Synapse Analytics, which is a modern data warehousing offering on Azure.\n",
        "- Mean Absolute Error (MAE): An evaluation measure for any regression model. It is the average difference between predicted and actual values. This works well when dealing with small ranges of numbers.\n",
        "- Mean Absolute Percent Error (MAPE): An evaluation measure for any regression model. It is the percentage difference between the predicted and actual values. If the actual value is 0, MAPE will fail with a divide by 0 error, so it is not a good measure if the actual value can be 0. MAPE works best when you have large ranges of numbers.\n",
        "- Microservice: A lightweight, independent service. Typically, microservices have one job and communicate with each other using well-defined operations.\n",
        "- Node (input, output): An input or output connection point on a component. Each component will have 0 to 3 input nodes and 0 to 3 output nodes. Each input or output node has a specific type, such as DataFrameDirectory, TransformationDirectory, or UntrainedModelDirectory. An input of DataFrameDirectory can only attach to an output of the same type.\n",
        "- Overfitting: A situation which happens when a trained model latches onto the particular relationships within a training data set, but those particulars are not always indicative of the broader world.\n",
        "- Pipeline (Azure ML): A collection of components connected together in a defined order. The metaphor represents how data moves from a source (an initial dataset) and flows through components until it reaches a destination. There are two types of pipeline: training pipelines and inference pipelines.\n",
        "- Pipeline Asset: A component available within Azure Machine Learning. This includes datasets you have imported, sample datasets which come with the service, and different components to transform, train, evaluate, and deploy models.\n",
        "- Precision: A measure which calculates how frequently our predicted value is correct. It is defined as True Positives / (True Positives + False Positives).\n",
        "- R^2 (R-squared): An evaluation measure for linear regression models which ranges from 0-1, where 1 is the highest possible score.\n",
        "- Recall: A measure which calculates how frequently we correctly predict a value. It is defined as True Positives / (True Positives + False Negatives).\n",
        "- Receiver Operating Characteristic (ROC) curve: A plot which represents true positive versus false positive rates for a two-class model.\n",
        "- Reinforcement learning: A machine learning technique in which we train an agent to observe its environment and use those environmental clues to make a decision.\n",
        "- Root Mean Square Error (RMSE): An evaluation measure for any regression model. RMSE works best when you are concerned with large differences between the predicted and actual values.\n",
        "- Root Mean Square Log Error (RMSLE): An evaluation measure for any regression model. RMSLE works best when you are concerned with large percentage differences between the predicted and actual values.\n",
        "- Run (Azure ML): An attempt to train a model in Azure Machine Learning. This can be done through a pipeline in the Azure ML designer or through Automated ML.\n",
        "- Semi-supervised learning: A machine learning technique in which we have a small percentage of data with labels and a large percentage of unlabeled data.\n",
        "- Sink node: A node with no outputs. An example of a sink node is Web Service Output.\n",
        "- Source node: A node with no inputs. An example of a source node is any dataset you bring onto the canvas.\n",
        "- Supervised learning: A machine learning technique in which we have a known good answer for our label and attempt to learn from this label for inference purposes. The most common examples of this include classification and regression.\n",
        "- Unsupervised learning: A machine learning technique in which we do not have labels for our data. We use unsupervised learning techniques to try to discover what those labels should be. Clustering is the most common example of this."
      ],
      "metadata": {
        "id": "rVZ_RsI0a_IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "- [Pixel-level land cover classification](https://github.com/Azure/pixel_level_land_classification)\n",
        "- [Genetic Algorithms in Antennas and Smart Antennas Design Overview: Two Novel Antenna Systems for Triband GNSS Applications and a Circular Switched Parasitic Array for WiMax Applications Developments with the Use of Genetic Algorithms](https://www.hindawi.com/journals/ijap/2014/729208/)\n",
        "- [Genetic Algorithms](https://www2.econ.iastate.edu/tesfatsi/holland.gaintro.htm)\n",
        "- [15 Real-World Applications of Genetic Algorithms](https://www.brainz.org/15-real-world-applications-genetic-algorithms/)\n",
        "- [What is Genetic Programming?](https://www.genetic-programming.com/gpanimatedtutorial.html)\n",
        "- [What is the Team Data Science Process?](https://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview)\n",
        "- [Machine Learning Algorithm Cheat Sheet for Azure Machine Learning designer](https://learn.microsoft.com/en-us/azure/machine-learning/algorithm-cheat-sheet?view=azureml-api-1)\n",
        "- [Algorithm & component reference for Azure Machine Learning designer](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/component-reference?view=azureml-api-2&viewFallbackFrom=azureml-api-1)\n",
        "- [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
        "- [Evaluate automated machine learning experiment results](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2)\n",
        "- [MLOps](https://www.datarobot.com/platform/mlops/?redirect_source=algorithmia.com)\n",
        "- [](https://towardsdatascience.com/a-beginners-guide-to-reinforcement-learning-with-a-mario-bros-example-fa0e0563aeb7)\n",
        "- [Data featurization in automated machine learning](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features?view=azureml-api-1)\n",
        "- [ML.NET: An open source and cross-platform machine learning framework](https://dotnet.microsoft.com/en-us/apps/machinelearning-ai/ml-dotnet)\n",
        "- [What is Machine Learning Server](https://learn.microsoft.com/en-us/machine-learning-server/what-is-machine-learning-server)\n",
        "- [Boosted Decision Tree Regression component](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/boosted-decision-tree-regression?view=azureml-api-2)"
      ],
      "metadata": {
        "id": "hCSxpZ12WYLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer Vision\n",
        "What Is Computer Vision?\n",
        "\n",
        "Use of Al to extract latent information from visual inputs\n",
        "\n",
        "- Analyzes visual information from images, video files, and cameras\n",
        "- Aims to imitate how the human brain processes visual data\n",
        "- Complexity added by multiple types of information in images\n",
        "  - Detect objects, faces, inferred context and actions, all in a single image\n",
        "\n",
        "What Problems Does Computer Vision Address?\n",
        "\n",
        "- Semantic segmentation\n",
        "- Object detection\n",
        "- Image classification\n",
        "- Facial recognition\n",
        "- Optical character recognition (OCR)\n",
        "\n",
        "Computer Vision in the Real World\n",
        "\n",
        "Widely used and provides many benefits\n",
        "\n",
        "- Cellular phones\n",
        "- Safety Security\n",
        "- Social media\n",
        "- Autonomous vehicles\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "At the end of this lesson, you will be able to:\n",
        "\n",
        "- Extract insights from images\n",
        ". Build custom image classification solutions\n",
        "- Detect, analyze, and recognize faces\n",
        "- Analyze text using optical character recognition\n",
        "- Create solutions to read typed and handwritten documents\n",
        "- Extract the key-value pair and tables in forms\n",
        "- Add Azure Computer Vision services into applications\n",
        "\n",
        "Computer vision attempts to provide solutions for several core workloads. Each workload is geared towards handling the different types of data that can appear in visual inputs. These workloads include:\n",
        "\n",
        "- Content Tagging is the process of analyzing images to identify well-known objects and attaching labels to each of them.\n",
        "- Object Detection refers to the process of identifying entities contained within an image.\n",
        "- Describe Images involves using artificial intelligence to understand the salient content in a photograph.\n",
        "- Image Classification uses machine learning models to classify or categorize photos based on their primary subject matter.\n",
        "- Facial Recognition refers to detecting human faces within an image and then analyzing and identifying those faces.\n",
        "- Read Text uses artificial intelligence to extract text from images and documents using optical character recognition or OCR.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGctco8_bNQC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qsgn3xW-ddH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resources\n",
        "- [customvision](https://www.customvision.ai/)\n",
        "- [Computer Vision API (v3.1)](https://westcentralus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-1-ga/operations/56f91f2e778daf14a499f21b)\n",
        "- [Azure AI Services](https://azure.microsoft.com/en-us/products/ai-services/)\n",
        "- [(Quickstart: Azure AI Vision v3.2 GA Read](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/quickstarts-sdk/client-library?pivots=programming-language-csharp&tabs=windows%2Cvisual-studio)\n",
        "- [Image segmentation](https://en.wikipedia.org/wiki/Image_segmentation)\n",
        "- [ML.NET Tutorial - Get started in 10 minutes](https://dotnet.microsoft.com/en-us/learn/ml-dotnet/get-started-tutorial/intro)"
      ],
      "metadata": {
        "id": "5MUlD41udd9J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNGEmltFeYD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML for Trading\n",
        "\n",
        "Three parts of teh course\n",
        "\n",
        "1. Manipulating Financial Data in Python\n",
        "2. Computational Investing\n",
        "3. Learning Algorithms for Trading\n",
        "\n",
        "Books\n",
        "- [Python For Finance, HillPish](https://github.com/yhilpisch/py4fi2nd)\n",
        "- [What Hedge Funds Really Do, Philip J. Romeo]()\n",
        "- [Machine Learning, Mitchell]()"
      ],
      "metadata": {
        "id": "dJHJ3IyCeYdO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUZykySDeku1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JPtxyhlepZlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Bollinger Bands.\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def symbol_to_path(symbol, base_dir=\"data\"):\n",
        "    \"\"\"Return CSV file path given ticker symbol.\"\"\"\n",
        "    return os.path.join(base_dir, \"{}.csv\".format(str(symbol)))\n",
        "\n",
        "\n",
        "def get_data(symbols, dates):\n",
        "    \"\"\"Read stock data (adjusted close) for given symbols from CSV files.\"\"\"\n",
        "    df = pd.DataFrame(index=dates)\n",
        "    if 'SPY' not in symbols:  # add SPY for reference, if absent\n",
        "        symbols.insert(0, 'SPY')\n",
        "\n",
        "    for symbol in symbols:\n",
        "        df_temp = pd.read_csv(symbol_to_path(symbol), index_col='Date',\n",
        "                parse_dates=True, usecols=['Date', 'Adj Close'], na_values=['nan'])\n",
        "        df_temp = df_temp.rename(columns={'Adj Close': symbol})\n",
        "        df = df.join(df_temp)\n",
        "        if symbol == 'SPY':  # drop dates SPY did not trade\n",
        "            df = df.dropna(subset=[\"SPY\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def plot_data(df, title=\"Stock prices\"):\n",
        "    \"\"\"Plot stock prices with a custom title and meaningful axis labels.\"\"\"\n",
        "    ax = df.plot(title=title, fontsize=12)\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(\"Price\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_rolling_mean(values, window):\n",
        "    \"\"\"Return rolling mean of given values, using specified window size.\"\"\"\n",
        "    return pd.rolling_mean(values, window=window)\n",
        "\n",
        "\n",
        "def get_rolling_std(values, window):\n",
        "    \"\"\"Return rolling standard deviation of given values, using specified window size.\"\"\"\n",
        "    # TODO: Compute and return rolling standard deviation\n",
        "\n",
        "\n",
        "def get_bollinger_bands(rm, rstd):\n",
        "    \"\"\"Return upper and lower Bollinger Bands.\"\"\"\n",
        "    # TODO: Compute upper_band and lower_band\n",
        "    return upper_band, lower_band\n",
        "\n",
        "\n",
        "def test_run():\n",
        "    # Read data\n",
        "    dates = pd.date_range('2012-01-01', '2012-12-31')\n",
        "    symbols = ['SPY']\n",
        "    df = get_data(symbols, dates)\n",
        "\n",
        "    # Compute Bollinger Bands\n",
        "    # 1. Compute rolling mean\n",
        "    rm_SPY = get_rolling_mean(df['SPY'], window=20)\n",
        "\n",
        "    # 2. Compute rolling standard deviation\n",
        "    rstd_SPY = get_rolling_std(df['SPY'], window=20)\n",
        "\n",
        "    # 3. Compute upper and lower bands\n",
        "    upper_band, lower_band = get_bollinger_bands(rm_SPY, rstd_SPY)\n",
        "\n",
        "    # Plot raw SPY values, rolling mean and Bollinger Bands\n",
        "    ax = df['SPY'].plot(title=\"Bollinger Bands\", label='SPY')\n",
        "    rm_SPY.plot(label='Rolling mean', ax=ax)\n",
        "    upper_band.plot(label='upper band', ax=ax)\n",
        "    lower_band.plot(label='lower band', ax=ax)\n",
        "\n",
        "    # Add axis labels and legend\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(\"Price\")\n",
        "    ax.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_run()\n"
      ],
      "metadata": {
        "id": "Byo3TJOnpbdn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}